{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 使用Transformer+Multitask+MLP，对给定的小时级u,v，给出小时级power_total以及capacity_total",
   "id": "487e4b99ba821ea7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义数据集及其处理方式。定义对于capacity的数据集",
   "id": "ab0560ebca09a10e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T05:33:01.388036Z",
     "start_time": "2024-12-22T05:31:06.244665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = r'E:\\PKU_ThirdGrade_Autumn\\机器学习基础'\n",
    "u_wind = []\n",
    "v_wind = []\n",
    "capacity = []\n",
    "power = []\n",
    "sample_number = [0,1000,2000,3000,4000,5000]\n",
    "for j in range(1,6):\n",
    "    for i in range(sample_number[j-1],sample_number[j]):\n",
    "        if i == 4014:\n",
    "            continue\n",
    "        u_file = path + rf'\\Results_{j}\\data_{i}\\u.csv'\n",
    "        v_file = path + rf'\\Results_{j}\\data_{i}\\v.csv'\n",
    "        capacity_file = path + rf'\\Results_{j}\\data_{i}\\capacity.csv'\n",
    "        power_file = path + rf'\\Results_{j}\\data_{i}\\power.csv'\n",
    "        df = pd.read_csv(u_file,header = None)\n",
    "        u_wind.append(df.iloc[:,0].values)\n",
    "        df = pd.read_csv(v_file,header = None)\n",
    "        v_wind.append(df.iloc[:,0].values)\n",
    "        df = pd.read_csv(power_file)\n",
    "        power.append(df.iloc[2:,10].values)\n",
    "        df = pd.read_csv(capacity_file)\n",
    "        capacity.append(df.iloc[1:,10].values)\n",
    "    \n",
    "u_wind = np.array(u_wind)\n",
    "v_wind = np.array(v_wind)\n",
    "capacity = np.array(capacity)\n",
    "power = np.array(power)\n",
    "print(u_wind.shape)\n",
    "print(v_wind.shape)\n",
    "print(capacity.shape)\n",
    "print(power.shape)"
   ],
   "id": "ed591deb115f56ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 8760)\n",
      "(4999, 8760)\n",
      "(4999, 12)\n",
      "(4999, 8760)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T05:33:10.743600Z",
     "start_time": "2024-12-22T05:33:10.736709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "u_wind = np.transpose(u_wind)\n",
    "v_wind = np.transpose(v_wind)\n",
    "capacity = np.transpose(capacity)\n",
    "power = np.transpose(power)\n",
    "print(u_wind.shape)\n",
    "print(v_wind.shape)\n",
    "print(capacity.shape)\n",
    "print(power.shape)\n",
    "input_size = u_wind.shape[0] \n",
    "output_capacity_size = capacity.shape[0]\n",
    "output_power_size = power.shape[0]"
   ],
   "id": "8514cc79e97b22f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 4999)\n",
      "(8760, 4999)\n",
      "(12, 4999)\n",
      "(8760, 4999)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T05:59:35.018916Z",
     "start_time": "2024-12-22T05:59:31.343926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_number = 4999\n",
    "def data_initialization(u_wind,v_wind,capacity,power):\n",
    "    input_merged, target1, target2 = [], [], []\n",
    "    for i in range(sample_number):\n",
    "        u_wind_sample = list(u_wind[:,i])\n",
    "        v_wind_sample = list(v_wind[:,i])\n",
    "        capacity_sample = list(capacity[:,i])\n",
    "        power_sample = list(power[:,i])\n",
    "        u_wind_sample = np.array(u_wind_sample)\n",
    "        v_wind_sample = np.array(v_wind_sample)\n",
    "        input_sample = np.column_stack((u_wind_sample, v_wind_sample))\n",
    "        input_merged.append(input_sample)\n",
    "        target1.append(capacity_sample)\n",
    "        target2.append(power_sample)\n",
    "        \n",
    "    return np.array(input_merged), np.array(target1), np.array(target2)\n",
    "\n",
    "class dataset_to_Dataset(Dataset):\n",
    "    def __init__(self,data_input_merged,data_target):\n",
    "        self.len = data_input_merged.shape[0]\n",
    "        print(data_input_merged.shape)\n",
    "        print(data_target.shape)\n",
    "        self.input_merged = torch.from_numpy(data_input_merged)\n",
    "        self.target1 = torch.from_numpy(data_target)\n",
    "        self.target1_normalized = ((self.target1 - self.target1.mean(dim=0))) / self.target1.std(dim=0)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        return self.input_merged[index,:,:],self.target1_normalized[index,:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "def dataset_split_6sets(data_input_merged, data_target1,data_target2, ratio=0.9):\n",
    "    split_index = int(ratio*sample_number)\n",
    "    train_input_merged = data_input_merged[:split_index,:]\n",
    "    train_target1 = data_target1[:split_index,:]\n",
    "    train_target2 = data_target2[:split_index,:]\n",
    "    test_input_merged = data_input_merged[split_index:,:]\n",
    "    test_target1 = data_target1[split_index:,:]\n",
    "    test_target2 = data_target2[split_index:,:]\n",
    "    return train_input_merged, train_target1,train_target2,test_input_merged, test_target1,test_target2"
   ],
   "id": "54246665ce01f175",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 搭建Transformer+Multitask+MLP",
   "id": "4810cb2b91e4d9ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T05:59:37.737881Z",
     "start_time": "2024-12-22T05:59:37.732293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, seq_len, num_heads=8, num_layers=6, ff_dim=64, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim,ff_dim)\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1,seq_len,ff_dim))\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model = ff_dim,\n",
    "            nhead = num_heads,\n",
    "            dim_feedforward = ff_dim,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(self.encoder_layer,num_layers=num_layers)\n",
    "        self.fc_out = nn.Linear(ff_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.positional_encoding\n",
    "        x = self.encoder(x)\n",
    "        output = self.fc_out(x.mean(dim=1))\n",
    "        return output\n",
    "    \n",
    "input_dim = 2\n",
    "output_dim = 12\n",
    "seq_len = 8760"
   ],
   "id": "642bf43247e4e8ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 开始训练",
   "id": "90973744e1be3f0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T06:09:37.660414Z",
     "start_time": "2024-12-22T06:09:17.304570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "# Example inputs\n",
    "BATCH_SIZE = 64\n",
    "LEARN_RATE = 1e-3\n",
    "\n",
    "dataset_input_merged, dataset_target1,dataset_target2 = data_initialization(u_wind,v_wind, capacity, power)\n",
    "print(dataset_input_merged.shape)\n",
    "print(dataset_target1.shape)\n",
    "print(dataset_target2.shape)\n",
    "dataset_input_merged = dataset_input_merged.astype(np.float32)\n",
    "dataset_target1 = dataset_target1.astype(np.float32)\n",
    "dataset_target2 = dataset_target2.astype(np.float32)\n",
    "\n",
    "train_input_merged, train_target1,train_target2,test_input_merged, test_target1,test_target2 = dataset_split_6sets(dataset_input_merged, dataset_target1,dataset_target2)\n",
    "train_set = dataset_to_Dataset(train_input_merged,train_target1)\n",
    "\n",
    "train_set_iter = DataLoader(dataset=train_set,# 将数据封装进Dataloader类\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True,  # 打乱batch与batch之间的顺序\n",
    "                            drop_last=True)# drop_last = True表示最后不够一个batch就舍弃那些多余的数据\n"
   ],
   "id": "c292f4317c88fdd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 8760, 2) (4999, 12) (4999, 8760)\n",
      "(4999, 8760, 2)\n",
      "(4999, 12)\n",
      "(4999, 8760)\n",
      "(4499, 8760, 2)\n",
      "(4499, 8760)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T06:10:39.618111Z",
     "start_time": "2024-12-22T06:10:18.827899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCH = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = TransformerModel(input_dim, output_dim,seq_len).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARN_RATE)\n",
    "\n",
    "BATCH_SIZE =64\n",
    "loss_plot = []\n",
    "input_size = 8760\n",
    "capacity_size = 12\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    loss_print = []\n",
    "    for batch_idx, (x, y1) in enumerate(train_set_iter):\n",
    "        x = x.reshape([BATCH_SIZE, input_size, 2])\n",
    "        x = x.to(device)\n",
    "        y1 = y1.reshape((BATCH_SIZE,capacity_size))\n",
    "        y1 = y1.to(device)\n",
    "        y1_pred = model(x)\n",
    "        loss = criterion(y1, y1_pred)\n",
    "        loss_print.append(loss.item())\n",
    "        # 三大步\n",
    "        # 网络的梯度值更为0\n",
    "        model.zero_grad()\n",
    "        # loss反向传播\n",
    "        loss.backward()\n",
    "        # 优化器更新\n",
    "        optimizer.step()\n",
    "    print(f'{epoch} of loss: LSTM+Multitask+MLP:loss:',sum(loss_print)/len(loss_print))\n",
    "    loss_plot.append(sum(loss_print)/len(loss_print))\n",
    "        \n",
    "end = time.perf_counter()\n",
    "print('训练时间为：{:.2f}s'.format(end-start))"
   ],
   "id": "74316796cb766622",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.83 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 25\u001B[0m\n\u001B[0;32m     23\u001B[0m y1 \u001B[38;5;241m=\u001B[39m y1\u001B[38;5;241m.\u001B[39mreshape((BATCH_SIZE,power_size))\n\u001B[0;32m     24\u001B[0m y1 \u001B[38;5;241m=\u001B[39m y1\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 25\u001B[0m y1_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(y1, y1_pred)\n\u001B[0;32m     27\u001B[0m loss_print\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[4], line 24\u001B[0m, in \u001B[0;36mTransformerModel.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     22\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x)\n\u001B[0;32m     23\u001B[0m x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositional_encoding\n\u001B[1;32m---> 24\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc_out(x)\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:415\u001B[0m, in \u001B[0;36mTransformerEncoder.forward\u001B[1;34m(self, src, mask, src_key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m    412\u001B[0m is_causal \u001B[38;5;241m=\u001B[39m _detect_is_causal_mask(mask, is_causal, seq_len)\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m mod \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m--> 415\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mmod\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_key_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc_key_padding_mask_for_layers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_nested:\n\u001B[0;32m    418\u001B[0m     output \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mto_padded_tensor(\u001B[38;5;241m0.\u001B[39m, src\u001B[38;5;241m.\u001B[39msize())\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:749\u001B[0m, in \u001B[0;36mTransformerEncoderLayer.forward\u001B[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m    747\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ff_block(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x))\n\u001B[0;32m    748\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 749\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sa_block\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc_key_padding_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    750\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ff_block(x))\n\u001B[0;32m    752\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:757\u001B[0m, in \u001B[0;36mTransformerEncoderLayer._sa_block\u001B[1;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sa_block\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor,\n\u001B[0;32m    756\u001B[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 757\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself_attn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mkey_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_padding_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    760\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mneed_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    761\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout1(x)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1266\u001B[0m, in \u001B[0;36mMultiheadAttention.forward\u001B[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001B[0m\n\u001B[0;32m   1252\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmulti_head_attention_forward(\n\u001B[0;32m   1253\u001B[0m         query, key, value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_dim, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads,\n\u001B[0;32m   1254\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_proj_weight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_proj_bias,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1263\u001B[0m         average_attn_weights\u001B[38;5;241m=\u001B[39maverage_attn_weights,\n\u001B[0;32m   1264\u001B[0m         is_causal\u001B[38;5;241m=\u001B[39mis_causal)\n\u001B[0;32m   1265\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1266\u001B[0m     attn_output, attn_output_weights \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_head_attention_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1267\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1268\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_proj_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43min_proj_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1269\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias_k\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias_v\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_zero_attn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1270\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mout_proj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1272\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_padding_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_padding_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1273\u001B[0m \u001B[43m        \u001B[49m\u001B[43mneed_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mneed_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1274\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattn_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1275\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage_attn_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage_attn_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1276\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first \u001B[38;5;129;01mand\u001B[39;00m is_batched:\n\u001B[0;32m   1278\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m), attn_output_weights\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:5364\u001B[0m, in \u001B[0;36mmulti_head_attention_forward\u001B[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001B[0m\n\u001B[0;32m   5362\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_separate_proj_weight:\n\u001B[0;32m   5363\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m in_proj_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_separate_proj_weight is False but in_proj_weight is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 5364\u001B[0m     q, k, v \u001B[38;5;241m=\u001B[39m \u001B[43m_in_projection_packed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_proj_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_proj_bias\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5365\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   5366\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m q_proj_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_separate_proj_weight is True but q_proj_weight is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\functional.py:4884\u001B[0m, in \u001B[0;36m_in_projection_packed\u001B[1;34m(q, k, v, w, b)\u001B[0m\n\u001B[0;32m   4881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mis\u001B[39;00m v:\n\u001B[0;32m   4882\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m q \u001B[38;5;129;01mis\u001B[39;00m k:\n\u001B[0;32m   4883\u001B[0m         \u001B[38;5;66;03m# self-attention\u001B[39;00m\n\u001B[1;32m-> 4884\u001B[0m         proj \u001B[38;5;241m=\u001B[39m \u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4885\u001B[0m         \u001B[38;5;66;03m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001B[39;00m\n\u001B[0;32m   4886\u001B[0m         proj \u001B[38;5;241m=\u001B[39m proj\u001B[38;5;241m.\u001B[39munflatten(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, (\u001B[38;5;241m3\u001B[39m, E))\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mcontiguous()\n",
      "\u001B[1;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 12.83 GiB. GPU "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "torch.save(model.state_dict(), 'transformer_normalization_full_2.pt')",
   "id": "2800c8ffaba7f30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.title(\"loss curve\")"
   ],
   "id": "406ecb014f3eb40a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 检测预测效果",
   "id": "f4c1a0f136c4b6cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = TransformerModel(input_dim, output_dim,seq_len).to(device)\n",
    "model.load_state_dict(torch.load('transformer_normalization_full_2.pt'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "test_set = dataset_to_Dataset(test_input_merged,test_target2)\n",
    "test_set_iter = DataLoader(dataset=test_set,batch_size=BATCH_SIZE,drop_last=True)\n",
    "\n",
    "loss_data = []\n",
    "y1_pred_data = []\n",
    "y1_ref_data = []\n",
    "for batch_idx, (x, y1) in enumerate(test_set_iter):\n",
    "    x = x.reshape([BATCH_SIZE, input_size, 2])\n",
    "    x = x.to(device)\n",
    "    y1 = y1.reshape((BATCH_SIZE,capacity_size))\n",
    "    y1 = y1.to(device)\n",
    "    y1_pred = model(x)\n",
    "    loss = criterion(y1, y1_pred)\n",
    "    print(loss.item())\n",
    "    loss_data.append(loss.item())\n",
    "    y1_pred_data.append(y1_pred.detach().cpu().numpy())\n",
    "    y1_ref_data.append(y1.detach().cpu().numpy())\n",
    "    print(f\"{batch_idx} has been finished\")    "
   ],
   "id": "ab853330e4714e93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(loss_data)\n",
    "plt.plot(loss_data)"
   ],
   "id": "15cb33fdf629c39e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(y1_pred_data[0].shape)\n",
    "y1_pred_data = np.concatenate(y1_pred_data,axis=0)\n",
    "print(y1_pred_data.shape)"
   ],
   "id": "95a82daf34b0f986"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(y1_ref_data[0].shape)\n",
    "y1_ref_data = np.concatenate(y1_ref_data,axis=0)\n",
    "print(y1_ref_data.shape)"
   ],
   "id": "13358fb78e55ac81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(y1_ref_data[0])\n",
    "print(y1_pred_data[0])"
   ],
   "id": "47720271b711568"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y1_relative_error = np.zeros_like(y1_ref_data)\n",
    "for i in range(500):\n",
    "    for j in range(12):\n",
    "        if y1_ref_data[i,j] <= 0.01:\n",
    "            y1_relative_error[i,j] = np.abs((y1_ref_data[i,j] - y1_pred_data[i,j]))\n",
    "        else:\n",
    "            y1_relative_error[i,j] = np.abs((y1_ref_data[i,j] - y1_pred_data[i,j]) / y1_ref_data[i,j])\n",
    "\n",
    "print(y1_relative_error.shape)\n",
    "y1_relative_error[0]\n",
    "\n",
    "y1_relative_error_mean = 0\n",
    "for i in range(500):\n",
    "    y1_relative_error_mean += np.mean(y1_relative_error[i,:])\n",
    "y1_relative_error_mean /= 500\n",
    "y1_relative_error_mean"
   ],
   "id": "bbc66a41fc357826"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(y1_relative_error[0])\n",
    "plt.title(\"loss curve\")\n",
    "print(np.mean(y1_relative_error[0]))"
   ],
   "id": "e67fa9c44a1e23bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(y1_ref_data[0])\n",
    "plt.plot(y1_pred_data[0])"
   ],
   "id": "9fcf743044c9a6d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
