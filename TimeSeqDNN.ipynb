{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 时序神经网络综述 参考资料：https://blog.csdn.net/zy_dreamer/article/details/136211280",
   "id": "adc1eb41e84cefae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 使用Transformer搭建时空神经网络。但是单独使用transformer对时间的预测结果不是很友好，如想使用，可以使用transformer与其他模型相结合的方式。 参考资料：https://blog.csdn.net/java1314777/article/details/134355884。 如想理解transformer请详见：https://blog.csdn.net/m0_37605642/article/details/135958384",
   "id": "39613cc9d2ca16c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:27:00.912298Z",
     "start_time": "2024-12-14T09:26:48.544894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiTaskTransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout, seq_len, capacity_len):\n",
    "        super(MultiTaskTransformerModel, self).__init__()\n",
    "        \n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, seq_len, d_model))\n",
    "        \n",
    "        # Input Linear Transformation\n",
    "        self.input_layer = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # Output Branches\n",
    "        # Hourly generation resource prediction (seq_len)\n",
    "        self.hourly_branch = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "        \n",
    "        # Capacity prediction (capacity_len)\n",
    "        self.capacity_branch = nn.Sequential(\n",
    "            nn.Linear(seq_len * d_model, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, capacity_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add positional encoding\n",
    "        x = self.input_layer(x) + self.positional_encoding\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Hourly generation resource prediction\n",
    "        hourly_output = self.hourly_branch(x).squeeze(-1)\n",
    "        \n",
    "        # Capacity prediction\n",
    "        flat_features = x.flatten(start_dim=1)\n",
    "        capacity_output = self.capacity_branch(flat_features)\n",
    "\n",
    "        return hourly_output, capacity_output\n",
    "\n",
    "# Model parameters\n",
    "input_dim = 2           # Two input features: wind speed u and v\n",
    "d_model = 64            # Transformer embedding dimension\n",
    "nhead = 4               # Number of attention heads\n",
    "num_encoder_layers = 3  # Number of transformer layers\n",
    "dim_feedforward = 128   # Dimension of the feedforward layer\n",
    "dropout = 0.1           # Dropout rate\n",
    "seq_len = 8760          # Length of the time series (hours in a year)\n",
    "capacity_len = 176      # Length of the wind power capacity output\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiTaskTransformerModel(\n",
    "    input_dim, d_model, nhead, num_encoder_layers, dim_feedforward, dropout, seq_len, capacity_len\n",
    ")\n",
    "\n",
    "# Example inputs\n",
    "batch_size = 32\n",
    "inputs = torch.rand(batch_size, seq_len, input_dim)  # Random input tensor\n",
    "\n",
    "# Forward pass\n",
    "hourly_output, capacity_output = model(inputs)\n",
    "\n",
    "print(f\"Hourly Output Shape: {hourly_output.shape}\")  # Expected: (batch_size, seq_len)\n",
    "print(f\"Capacity Output Shape: {capacity_output.shape}\")  # Expected: (batch_size, capacity_len)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_hourly = nn.MSELoss()\n",
    "criterion_capacity = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Example target outputs\n",
    "hourly_target = torch.rand(batch_size, seq_len)\n",
    "capacity_target = torch.rand(batch_size, capacity_len)\n",
    "\n",
    "# Training step\n",
    "optimizer.zero_grad()\n",
    "hourly_pred, capacity_pred = model(inputs)\n",
    "\n",
    "loss_hourly = criterion_hourly(hourly_pred, hourly_target)\n",
    "loss_capacity = criterion_capacity(capacity_pred, capacity_target)\n",
    "\n",
    "# Combined loss\n",
    "loss = loss_hourly + loss_capacity\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Training Loss: {loss.item()}\")\n"
   ],
   "id": "c53972f3a33f0cbf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly Output Shape: torch.Size([32, 8760])\n",
      "Capacity Output Shape: torch.Size([32, 176])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 85\u001B[0m\n\u001B[0;32m     82\u001B[0m criterion_capacity \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[0;32m     84\u001B[0m \u001B[38;5;66;03m# Optimizer\u001B[39;00m\n\u001B[1;32m---> 85\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m \u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAdam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# Example target outputs\u001B[39;00m\n\u001B[0;32m     88\u001B[0m hourly_target \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(batch_size, seq_len)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adam.py:45\u001B[0m, in \u001B[0;36mAdam.__init__\u001B[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001B[0m\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid weight_decay value: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweight_decay\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     41\u001B[0m defaults \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(lr\u001B[38;5;241m=\u001B[39mlr, betas\u001B[38;5;241m=\u001B[39mbetas, eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m     42\u001B[0m                 weight_decay\u001B[38;5;241m=\u001B[39mweight_decay, amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[0;32m     43\u001B[0m                 maximize\u001B[38;5;241m=\u001B[39mmaximize, foreach\u001B[38;5;241m=\u001B[39mforeach, capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[0;32m     44\u001B[0m                 differentiable\u001B[38;5;241m=\u001B[39mdifferentiable, fused\u001B[38;5;241m=\u001B[39mfused)\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefaults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fused:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m differentiable:\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:284\u001B[0m, in \u001B[0;36mOptimizer.__init__\u001B[1;34m(self, params, defaults)\u001B[0m\n\u001B[0;32m    281\u001B[0m     param_groups \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: param_groups}]\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param_group \u001B[38;5;129;01min\u001B[39;00m param_groups:\n\u001B[1;32m--> 284\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_param_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_group\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# which I don't think exists\u001B[39;00m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001B[39;00m\n\u001B[0;32m    289\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warned_capturable_if_run_uncaptured \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_compile.py:22\u001B[0m, in \u001B[0;36m_disable_dynamo.<locals>.inner\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fn)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 22\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_dynamo\u001B[39;00m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mdisable(fn, recursive)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:64\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mjit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_builtins\u001B[39;00m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# Wrap manual_seed with the disable decorator.\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;66;03m# Can't do it at its implementation due to dependency issues.\u001B[39;00m\n\u001B[1;32m---> 64\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed \u001B[38;5;241m=\u001B[39m \u001B[43mdisable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmanual_seed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Add the new manual_seed to the builtin registry.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39m_builtins\u001B[38;5;241m.\u001B[39m_register_builtin(torch\u001B[38;5;241m.\u001B[39mmanual_seed, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maten::manual_seed\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\decorators.py:50\u001B[0m, in \u001B[0;36mdisable\u001B[1;34m(fn, recursive)\u001B[0m\n\u001B[0;32m     48\u001B[0m         fn \u001B[38;5;241m=\u001B[39m innermost_fn(fn)\n\u001B[0;32m     49\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(fn)\n\u001B[1;32m---> 50\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDisableContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DisableContext()\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:410\u001B[0m, in \u001B[0;36m_TorchDynamoContext.__call__\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    408\u001B[0m     filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m--> 410\u001B[0m     (filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mtrace_rules\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    411\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m    412\u001B[0m         \u001B[38;5;28mgetattr\u001B[39m(fn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__name__\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_call_impl\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_wrapped_call_impl\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    413\u001B[0m     )\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m filename \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m DONT_WRAP_FILES\n\u001B[0;32m    415\u001B[0m ):\n\u001B[0;32m    416\u001B[0m     \u001B[38;5;66;03m# call to a builtin without a frame for us to capture\u001B[39;00m\n\u001B[0;32m    417\u001B[0m     fn \u001B[38;5;241m=\u001B[39m external_utils\u001B[38;5;241m.\u001B[39mwrap_inline(fn)\n\u001B[0;32m    419\u001B[0m callback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:3378\u001B[0m, in \u001B[0;36mcheck\u001B[1;34m(obj, is_inlined_call)\u001B[0m\n\u001B[0;32m   3377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck\u001B[39m(obj, is_inlined_call\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m-> 3378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcheck_verbose\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_inlined_call\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mskipped\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:3361\u001B[0m, in \u001B[0;36mcheck_verbose\u001B[1;34m(obj, is_inlined_call)\u001B[0m\n\u001B[0;32m   3358\u001B[0m     fi \u001B[38;5;241m=\u001B[39m FunctionInfo(obj, \u001B[38;5;28;01mNone\u001B[39;00m, getfile(obj), \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   3360\u001B[0m \u001B[38;5;66;03m# Consulte the central trace rules defined in torch._dynamo.trace_rules.\u001B[39;00m\n\u001B[1;32m-> 3361\u001B[0m rule \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dynamo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace_rules\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlookup_inner\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3362\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpy_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_inlined_call\u001B[49m\n\u001B[0;32m   3363\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rule \u001B[38;5;129;01min\u001B[39;00m [UserFunctionVariable, FunctorchHigherOrderVariable]:\n\u001B[0;32m   3365\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SkipResult(\n\u001B[0;32m   3366\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   3367\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minlined according trace_rules.lookup\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   3368\u001B[0m     )\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:3442\u001B[0m, in \u001B[0;36mlookup_inner\u001B[1;34m(obj, name, filename, is_direct_call)\u001B[0m\n\u001B[0;32m   3440\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_aten_op_or_tensor_method(obj):\n\u001B[0;32m   3441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m TorchInGraphFunctionVariable\n\u001B[1;32m-> 3442\u001B[0m rule \u001B[38;5;241m=\u001B[39m \u001B[43mget_torch_obj_rule_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mget(obj, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   3443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m rule \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m rule\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:2782\u001B[0m, in \u001B[0;36mget_torch_obj_rule_map\u001B[1;34m()\u001B[0m\n\u001B[0;32m   2780\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m torch_name_rule_map:\n\u001B[0;32m   2781\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m m\u001B[38;5;241m.\u001B[39mitems():  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m-> 2782\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mload_object\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2783\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2784\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m d \u001B[38;5;129;01mand\u001B[39;00m d[obj] \u001B[38;5;241m!=\u001B[39m v:\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:2807\u001B[0m, in \u001B[0;36mload_object\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m   2805\u001B[0m x \u001B[38;5;241m=\u001B[39m name\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2806\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(x) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m-> 2807\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[43m_load_obj_from_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2808\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, x[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m   2809\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\trace_rules.py:2795\u001B[0m, in \u001B[0;36m_load_obj_from_str\u001B[1;34m(fully_qualified_name)\u001B[0m\n\u001B[0;32m   2793\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_obj_from_str\u001B[39m(fully_qualified_name):\n\u001B[0;32m   2794\u001B[0m     module, obj_name \u001B[38;5;241m=\u001B[39m fully_qualified_name\u001B[38;5;241m.\u001B[39mrsplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, maxsplit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m-> 2795\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m, obj_name)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\distributed\\_tensor\\__init__.py:6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Import all builtin dist tensor ops\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributed\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tensor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributed\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tensor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrandom\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mrandom\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributed\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tensor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compute_local_shape\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\distributed\\_tensor\\ops\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membedding_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmatrix_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmath_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\distributed\\_tensor\\ops\\embedding_ops.py:8\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cast, List, Optional\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributed\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_functional_collectives\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mfuncol\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributed\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tensor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mop_schema\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     10\u001B[0m     OpSchema,\n\u001B[0;32m     11\u001B[0m     OpStrategy,\n\u001B[0;32m     12\u001B[0m     PlacementStrategy,\n\u001B[0;32m     13\u001B[0m     StrategyType,\n\u001B[0;32m     14\u001B[0m )\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistributed\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_tensor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     16\u001B[0m     generate_redistribute_costs,\n\u001B[0;32m     17\u001B[0m     is_tensor_shardable,\n\u001B[0;32m     18\u001B[0m     register_op_strategy,\n\u001B[0;32m     19\u001B[0m )\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\distributed\\_functional_collectives.py:920\u001B[0m\n\u001B[0;32m    918\u001B[0m c10_lib \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mLibrary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mc10d_functional\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDEF\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    919\u001B[0m c10_lib_impl \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mLibrary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mc10d_functional\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIMPL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 920\u001B[0m \u001B[43m_register_ops\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    922\u001B[0m _c10_lib_impl \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mlibrary\u001B[38;5;241m.\u001B[39mLibrary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_c10d_functional\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIMPL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    923\u001B[0m _c10_lib_impl\u001B[38;5;241m.\u001B[39mimpl(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall_reduce\u001B[39m\u001B[38;5;124m\"\u001B[39m, _all_reduce_meta, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMeta\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\distributed\\_functional_collectives.py:911\u001B[0m, in \u001B[0;36m_register_ops\u001B[1;34m()\u001B[0m\n\u001B[0;32m    909\u001B[0m c10_lib\u001B[38;5;241m.\u001B[39mdefine(op_def, tags\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mTag\u001B[38;5;241m.\u001B[39mpt2_compliant_tag)\n\u001B[0;32m    910\u001B[0m c10_lib_impl\u001B[38;5;241m.\u001B[39mimpl(op_name, backend_impl, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompositeExplicitAutograd\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 911\u001B[0m \u001B[43mimpl_abstract\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mc10d_functional::\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mop_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m(meta_impl)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_custom_ops.py:253\u001B[0m, in \u001B[0;36mimpl_abstract\u001B[1;34m(qualname, func)\u001B[0m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Register an abstract implementation for this operator.\u001B[39;00m\n\u001B[0;32m    183\u001B[0m \n\u001B[0;32m    184\u001B[0m \u001B[38;5;124;03mAn \"abstract implementation\" specifies the behavior of this operator on\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    249\u001B[0m \n\u001B[0;32m    250\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlibrary\u001B[39;00m\n\u001B[1;32m--> 253\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpl_abstract\u001B[49m\u001B[43m(\u001B[49m\u001B[43mqualname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\library.py:448\u001B[0m, in \u001B[0;36mimpl_abstract\u001B[1;34m(qualname, func, lib, _stacklevel)\u001B[0m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimpl_abstract\u001B[39m(qualname, func\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, lib\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, _stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Register an abstract implementation for this operator.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03m    An \"abstract implementation\" specifies the behavior of this operator on\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    446\u001B[0m \n\u001B[0;32m    447\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 448\u001B[0m     source \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_source\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_stacklevel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    449\u001B[0m     frame \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39m_getframe(_stacklevel)\n\u001B[0;32m    450\u001B[0m     caller_module \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39mgetmodule(frame)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\site-packages\\torch\\_library\\utils.py:39\u001B[0m, in \u001B[0;36mget_source\u001B[1;34m(stacklevel)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_source\u001B[39m(stacklevel: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[0;32m     31\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a string that represents the caller.\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m    Example: \"/path/to/foo.py:42\"\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;124;03m    etc.\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 39\u001B[0m     frame \u001B[38;5;241m=\u001B[39m \u001B[43minspect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetframeinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstacklevel\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m     source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mframe\u001B[38;5;241m.\u001B[39mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mframe\u001B[38;5;241m.\u001B[39mlineno\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m source\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\inspect.py:1688\u001B[0m, in \u001B[0;36mgetframeinfo\u001B[1;34m(frame, context)\u001B[0m\n\u001B[0;32m   1686\u001B[0m start \u001B[38;5;241m=\u001B[39m lineno \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m context\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[0;32m   1687\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1688\u001B[0m     lines, lnum \u001B[38;5;241m=\u001B[39m \u001B[43mfindsource\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1689\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m   1690\u001B[0m     lines \u001B[38;5;241m=\u001B[39m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\inspect.py:1062\u001B[0m, in \u001B[0;36mfindsource\u001B[1;34m(object)\u001B[0m\n\u001B[0;32m   1059\u001B[0m file \u001B[38;5;241m=\u001B[39m getsourcefile(\u001B[38;5;28mobject\u001B[39m)\n\u001B[0;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file:\n\u001B[0;32m   1061\u001B[0m     \u001B[38;5;66;03m# Invalidate cache if needed.\u001B[39;00m\n\u001B[1;32m-> 1062\u001B[0m     \u001B[43mlinecache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheckcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1063\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1064\u001B[0m     file \u001B[38;5;241m=\u001B[39m getfile(\u001B[38;5;28mobject\u001B[39m)\n",
      "File \u001B[1;32mE:\\Anaconda\\AnacondaInstall\\envs\\pytorch\\Lib\\linecache.py:72\u001B[0m, in \u001B[0;36mcheckcache\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m   \u001B[38;5;66;03m# no-op for files loaded via a __loader__\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 72\u001B[0m     stat \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(fullname)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     cache\u001B[38;5;241m.\u001B[39mpop(filename, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 卷积是为了跨时间步骤提取特征，我们这里可能不需要进行跨时间步骤提取特征的需求，故舍弃。参考资料为：https://blog.csdn.net/Leon_winter/article/details/100124146 使用TCN处理时间序列",
   "id": "8ee8b1f11eca5f13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, input_dim, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            in_channels = input_dim if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=(kernel_size-1), dilation=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class MultiTaskTCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_channels, seq_len, capacity_len, kernel_size=2, dropout=0.2):\n",
    "        super(MultiTaskTCNModel, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_dim, num_channels, kernel_size, dropout)\n",
    "        self.hourly_branch = nn.Sequential(\n",
    "            nn.Linear(num_channels[-1], num_channels[-1] // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_channels[-1] // 2, 1)\n",
    "        )\n",
    "        self.capacity_branch = nn.Sequential(\n",
    "            nn.Linear(seq_len * num_channels[-1], num_channels[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_channels[-1], capacity_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Reshape for Conv1d (batch, input_dim, seq_len)\n",
    "        features = self.tcn(x).permute(0, 2, 1)  # Reshape back (batch, seq_len, features)\n",
    "        hourly_output = self.hourly_branch(features).squeeze(-1)  # (batch, seq_len)\n",
    "        flat_features = features.flatten(start_dim=1)  # Flatten for capacity branch\n",
    "        capacity_output = self.capacity_branch(flat_features)  # (batch, capacity_len)\n",
    "        return hourly_output, capacity_output\n",
    "\n",
    "# Model parameters\n",
    "input_dim = 2           # Two input features: wind speed u and v\n",
    "num_channels = [16, 32, 64]  # TCN channel sizes for each layer\n",
    "seq_len = 8760          # Length of the time series (hours in a year)\n",
    "capacity_len = 176      # Length of the wind power capacity output\n",
    "kernel_size = 3         # Kernel size for TCN\n",
    "dropout = 0.1           # Dropout rate\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiTaskTCNModel(input_dim, num_channels, seq_len, capacity_len, kernel_size, dropout)\n",
    "\n",
    "# Example inputs\n",
    "batch_size = 32\n",
    "inputs = torch.rand(batch_size, seq_len, input_dim)  # Random input tensor\n",
    "\n",
    "# Forward pass\n",
    "hourly_output, capacity_output = model(inputs)\n",
    "\n",
    "print(f\"Hourly Output Shape: {hourly_output.shape}\")  # Expected: (batch_size, seq_len)\n",
    "print(f\"Capacity Output Shape: {capacity_output.shape}\")  # Expected: (batch_size, capacity_len)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_hourly = nn.MSELoss()\n",
    "criterion_capacity = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Example target outputs\n",
    "hourly_target = torch.rand(batch_size, seq_len)\n",
    "capacity_target = torch.rand(batch_size, capacity_len)\n",
    "\n",
    "# Training step\n",
    "optimizer.zero_grad()\n",
    "hourly_pred, capacity_pred = model(inputs)\n",
    "\n",
    "loss_hourly = criterion_hourly(hourly_pred, hourly_target)\n",
    "loss_capacity = criterion_capacity(capacity_pred, capacity_target)\n",
    "\n",
    "# Combined loss\n",
    "loss = loss_hourly + loss_capacity\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Training Loss: {loss.item()}\")\n"
   ],
   "id": "d0c97373d996fdf8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# （可以使用，既可以解决梯度消失和梯度爆炸问题，还能够训练较好的效果。参考资料：https://blog.csdn.net/mary19831/article/details/129570030 ）使用LSTM处理时间序列神经网络",
   "id": "9a0df81306b2df70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:48:12.476741Z",
     "start_time": "2024-12-14T09:48:09.756134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiTaskLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, seq_len, capacity_len, dropout):\n",
    "        super(MultiTaskLSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Hourly generation resource prediction branch\n",
    "        self.hourly_branch = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "        # Capacity prediction branch\n",
    "        self.capacity_branch = nn.Sequential(\n",
    "            nn.Linear(seq_len * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, capacity_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # print(type(lstm_out))\n",
    "        # print(lstm_out.shape)\n",
    "        # LSTM output: (batch, seq_len, hidden_dim)\n",
    "        hourly_output = self.hourly_branch(lstm_out).squeeze(-1)  # (batch, seq_len)\n",
    "\n",
    "        flat_features = lstm_out.flatten(start_dim=1)  # Flatten for capacity branch\n",
    "        capacity_output = self.capacity_branch(flat_features)  # (batch, capacity_len)\n",
    "\n",
    "        return hourly_output, capacity_output\n",
    "\n"
   ],
   "id": "f6aaf91488636e67",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:27:12.756424Z",
     "start_time": "2024-12-14T09:27:12.614625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modeltest = MultiTaskLSTMModel(2,64,2,8760,176,0.1)\n",
    "print(modeltest)"
   ],
   "id": "25a60d776ee6c9c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiTaskLSTMModel(\n",
      "  (lstm): LSTM(2, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (hourly_branch): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "  )\n",
      "  (capacity_branch): Sequential(\n",
      "    (0): Linear(in_features=560640, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=176, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T09:48:32.330767Z",
     "start_time": "2024-12-14T09:48:23.207342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model parameters\n",
    "input_dim = 2           # Two input features: wind speed u and v\n",
    "hidden_dim = 64         # Hidden dimension for LSTM\n",
    "num_layers = 2          # Number of LSTM layers\n",
    "seq_len = 8760          # Length of the time series (hours in a year)\n",
    "capacity_len = 176      # Length of the wind power capacity output\n",
    "dropout = 0.1           # Dropout rate\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiTaskLSTMModel(input_dim, hidden_dim, num_layers, seq_len, capacity_len, dropout)\n",
    "\n",
    "# Example inputs\n",
    "batch_size = 32\n",
    "inputs = torch.rand(batch_size, seq_len, input_dim)  # Random input tensor\n",
    "print(inputs.shape)\n",
    "# Forward pass\n",
    "hourly_output, capacity_output = model(inputs)\n",
    "\n",
    "print(f\"Hourly Output Shape: {hourly_output.shape}\")  # Expected: (batch_size, seq_len)\n",
    "print(f\"Capacity Output Shape: {capacity_output.shape}\")  # Expected: (batch_size, capacity_len)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_hourly = nn.MSELoss()\n",
    "criterion_capacity = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Example target outputs\n",
    "hourly_target = torch.rand(batch_size, seq_len)\n",
    "capacity_target = torch.rand(batch_size, capacity_len)\n",
    "\n",
    "# Training step\n",
    "optimizer.zero_grad()\n",
    "hourly_pred, capacity_pred = model(inputs)\n",
    "\n",
    "loss_hourly = criterion_hourly(hourly_pred, hourly_target)\n",
    "loss_capacity = criterion_capacity(capacity_pred, capacity_target)\n",
    "\n",
    "# Combined loss\n",
    "loss = loss_hourly + loss_capacity\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Training Loss: {loss.item()}\")\n"
   ],
   "id": "e076d3b75203c21a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8760, 2])\n",
      "Hourly Output Shape: torch.Size([32, 8760])\n",
      "Capacity Output Shape: torch.Size([32, 176])\n",
      "Training Loss: 0.8657733201980591\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SpatiotemporalLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len, capacity_len, dropout=0.1):\n",
    "        super(SpatiotemporalLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=1, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Hourly generation resource prediction branch\n",
    "        self.hourly_branch = nn.Linear(hidden_dim, 1)  # Directly map hidden state to output\n",
    "\n",
    "        # Capacity prediction branch\n",
    "        self.capacity_branch = nn.Sequential(\n",
    "            nn.Linear(seq_len * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, capacity_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM layer\n",
    "        lstm_out, _ = self.lstm(x)  # lstm_out shape: (batch_size, seq_len, hidden_dim)\n",
    "\n",
    "        # Hourly prediction: apply linear layer to each time step\n",
    "        hourly_output = self.hourly_branch(lstm_out).squeeze(-1)  # Shape: (batch_size, seq_len)\n",
    "\n",
    "        # Capacity prediction: flatten LSTM outputs and pass through MLP\n",
    "        flat_features = lstm_out.flatten(start_dim=1)  # Shape: (batch_size, seq_len * hidden_dim)\n",
    "        capacity_output = self.capacity_branch(flat_features)  # Shape: (batch_size, capacity_len)\n",
    "\n",
    "        return hourly_output, capacity_output\n"
   ],
   "id": "c233373c0369e922",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# （由于GRU比LSTM简单易训，但是表达能力可能没有LSTM好，故舍弃。参考资料：https://blog.csdn.net/Michale_L/article/details/122778270 ）使用GRU进行时间序列神经网络搭建",
   "id": "20c9c2fcc1549f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class MultiTaskGRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, seq_len, capacity_len, dropout):\n",
    "        super(MultiTaskGRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # Hourly generation resource prediction branch\n",
    "        self.hourly_branch = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)\n",
    "        )\n",
    "\n",
    "        # Capacity prediction branch\n",
    "        self.capacity_branch = nn.Sequential(\n",
    "            nn.Linear(seq_len * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, capacity_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)  # GRU output: (batch, seq_len, hidden_dim)\n",
    "        hourly_output = self.hourly_branch(gru_out).squeeze(-1)  # (batch, seq_len)\n",
    "\n",
    "        flat_features = gru_out.flatten(start_dim=1)  # Flatten for capacity branch\n",
    "        capacity_output = self.capacity_branch(flat_features)  # (batch, capacity_len)\n",
    "\n",
    "        return hourly_output, capacity_output\n",
    "\n",
    "# Model parameters\n",
    "input_dim = 2           # Two input features: wind speed u and v\n",
    "hidden_dim = 64         # Hidden dimension for GRU\n",
    "num_layers = 2          # Number of GRU layers\n",
    "seq_len = 8760          # Length of the time series (hours in a year)\n",
    "capacity_len = 176      # Length of the wind power capacity output\n",
    "dropout = 0.1           # Dropout rate\n",
    "\n",
    "# Initialize the model\n",
    "model = MultiTaskGRUModel(input_dim, hidden_dim, num_layers, seq_len, capacity_len, dropout)\n",
    "\n",
    "# Example inputs\n",
    "batch_size = 32\n",
    "inputs = torch.rand(batch_size, seq_len, input_dim)  # Random input tensor\n",
    "\n",
    "# Forward pass\n",
    "hourly_output, capacity_output = model(inputs)\n",
    "\n",
    "print(f\"Hourly Output Shape: {hourly_output.shape}\")  # Expected: (batch_size, seq_len)\n",
    "print(f\"Capacity Output Shape: {capacity_output.shape}\")  # Expected: (batch_size, capacity_len)\n",
    "\n",
    "# Define loss functions\n",
    "criterion_hourly = nn.MSELoss()\n",
    "criterion_capacity = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Example target outputs\n",
    "hourly_target = torch.rand(batch_size, seq_len)\n",
    "capacity_target = torch.rand(batch_size, capacity_len)\n",
    "\n",
    "# Training step\n",
    "optimizer.zero_grad()\n",
    "hourly_pred, capacity_pred = model(inputs)\n",
    "\n",
    "loss_hourly = criterion_hourly(hourly_pred, hourly_target)\n",
    "loss_capacity = criterion_capacity(capacity_pred, capacity_target)\n",
    "\n",
    "# Combined loss\n",
    "loss = loss_hourly + loss_capacity\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"Training Loss: {loss.item()}\")\n"
   ],
   "id": "8b2b8a095a4faf1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 一般的RNN由于不能解决梯度消失和梯度爆炸的问题，故一般不适用RNN。参考资料：https://blog.csdn.net/qq_51320133/article/details/138213246",
   "id": "9104741e51af3cef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 图神经网络。可以把我们需要的时间和离散空间的点传入进去，不过可能导致维度过大，处理时间长，且用不上我们提取到的特征。好处是，可以训练出可能存在的空间的关系，以帮助模型找到更好的效果。参考资料：https://blog.csdn.net/deephub/article/details/137769276",
   "id": "b5872424cb1017be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 个人觉得使用LSTM和GRU组合训练形成多元预测是最佳路径。 参考资料：https://blog.csdn.net/java1314777/article/details/134272675",
   "id": "3eb2b6edf1853931"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
